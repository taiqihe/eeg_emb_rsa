# Neural Correlates of Word Representation Vectors in Natural Language Processing Models

## Dependencies

- Matlab: [EEGLAB](https://sccn.ucsd.edu/eeglab/index.php), [ERPLAB](https://github.com/lucklab/erplab)
- Python>3.5: numpy, absl-py, textgrid, scipy, tensorflow, tensorflow_hub, nltk, matplotlib
- Perl
- [FastText](https://github.com/facebookresearch/fastText/)


## Preprocessing

### Scripts

- `transfer_transcription.py` takes story transcripts (plain text file, 1 sentence per line), and transfers the sentences to empty TextGrid files generated by Praat 
- `extract_intervals.py` pickles time points either from TextGrid (auto generated) or csv (human annotated) files
- `check_alignment.py` gives the errors between aligned and human annotated time points
- `proc_elist.py` generates new ERPLAB format eventlists from pickled aligned transcripts and old eventlists from EEGLAB/ERPLAB
- `serialize_epochs.py` converts epoched data to a serialized format that facilitates further processing 
- `save_all.praat` is a Praat script that saves multiple files at once (a feature the program lacks)
- `normalize_eventlists.sh` fixes inconsistencies between eventlists to make processing easier
- `gen_eventlist.m` extracts eventlists from EEG data
- `gen_data.m` is the main EEG data processing script, from filtering to generating epoched data


### Generating aligned word onsets

We use an automatic speech recognition (ASR) toolkit, [Montreal Forced Aligner](https://github.com/MontrealCorpusTools/Montreal-Forced-Aligner), to find the onset of each word from the story transcripts in the audio files. Since we have the eventcodes for the onset of each audio file, we can infer the onset of each word in the experiment if we know the onsets of the words in their audio files.

Aligned word onset data for the two stories are provided. To replicate the results, follow the steps below. You will need:
- Praat
- [Montreal Forced Aligner](https://github.com/MontrealCorpusTools/Montreal-Forced-Aligner)

1. Open all sound files in Praat, select all in the objects window, choose `Annotate-`  then `To TextGrid...`

2. Use `text` as the only tier name, no point tiers. Generate TextGrid files.

3. Open `save_all.praat` , while selecting all the TextGrid files, run the script and save the files in the sound folder.

4. Run `transfer_transcription.py` to put the actual texts into the TextGrid files.

5. Use MFA to align the words with sounds. A sample command looks like this (with the default pretrained English model and our pronunciation dictionary that added missing words):

   ```
   mfa align --clean TEC_source/ english_pronunciations.dict english TEC_outputs
   ```

7. Repeat for each story.

### Testing generated alignments

Hand annotated onsets for a subset of the words are provided. You can save both the generated onsets and annotated onsets as serialized pickle files with `extract_intervals.py` and run `check_alignment.py` to check the alignment errors (in milliseconds).

### Generating epoched data

1. Run `gen_eventlist.m` to extract the eventlists from the EEG files.
2. Run `normalize_eventlists.sh` to fix idiosyncratic inconsistencies in the generated eventlists
3. Use `proc_elist.py` to add word information from the audio-text alignments to the eventlists
4. Run `gen_data.m` to filter and epoch the EEG data and generate epochs for all words for each subject
5. Run `serialize_epochs.py` to prepare the data for the next steps

## Generating statistics and figures

### Scripts

- `cormat.py` is the main script that calculates various RSAs
- `plotting.py` contains functions that plots the figures in the paper
- `get_elmo_embs.py` requires TensorFlow, TensorFlow Hub. The script downloads the ELMo models and generates the contextualized embeddings from the story transcripts
- `gen_word_masks.py` requires NLTK, generates frequency based word lists as masks for RSAs

### Embeddings

Download FastText embeddings from https://fasttext.cc/docs/en/english-vectors.html (wiki-news-300d-1M was used in the paper). Alternatively, you can choose any text embedding file. The advantage of FastText is that it enables inferencing out-of-vocabulary words from trained sub-word embeddings.

Use `get_elmo_embs.py` to download the ELMo model and generate contextualized embeddings.

### Calculating RSAs

1. Run `gen_word_masks.py` with default settings to get the list of 100 most frequent words.

2. Use FastText or `get_elmo_embs.py` to generate embeddings. FastText command example:

    ````
   ./fasttext print-word-vectors cc.en.300.bin < top100_words.txt > top100_embs.txt
   ````

3. Run `cormat.py` to generate RSAs (post-baseline or moving window) and noise ceilings.

4. Run `plotting.py` to visualize results.


## Helper scripts
- `bootstrapping.py` is a simple helper script that generates bootstrapped confidence intervals
- `tokenizer.py` is an adapted version of the NLTK tokenizer, required by `transfer_transcription.py`
- `mystats.py` defines some statistical testing and correlation functions not easily found in existing packages
